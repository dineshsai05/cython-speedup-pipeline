# âš¡ Cython Speedup Pipeline

An optimized NLP text processing pipeline using **Cython** and **multiprocessing**, demonstrating performance improvements over pure Python on real-world datasets like **IMDb reviews** and **news headlines**.

This project shows how adding static typing and releasing Pythonâ€™s Global Interpreter Lock (GIL) in performance-critical code can lead to significant speedups â€” especially when processing large amounts of text.

![Benchmark Plot](results/benchmark_plot.png)

---

## ðŸ“Œ What Weâ€™re Doing

Natural language processing often involves tokenizing and normalizing large amounts of text (like news articles or movie reviews). In this project, we:

- Tokenize text data using `split()` logic
- Normalize word frequencies
- Compare runtime performance using:
  - **Pure Python**
  - **Cython-compiled functions**
  - **Cython + multiprocessing**

This lets us study how performance scales across different optimization techniques and datasets.

---

## ðŸš€ Why Time Reduces with Cython

- Cython allows adding **C-style static types** (`cdef int`, `double`, etc.)
- This removes dynamic Python overhead in tight loops
- Releasing the GIL with `nogil` in independent computations allows safe threading or multiprocessing
- As a result, Cython runs **faster** than interpreted Python â€” especially in CPU-heavy tasks like loops over big text corpora

---

## â“ Why Multiprocessing *Doesnâ€™t Help* for News Dataset

In the **news headlines dataset**, each text input is **very short** (5â€“10 words).  
Multiprocessing adds overhead for:

- Spawning processes
- Serializing data between processes
- Reconstructing the result

Since each unit of work (a headline) is **very small**, the overhead dominates â€” making multiprocessing slightly slower than single-threaded Cython.

> âœ… Multiprocessing shines only when **work per input is large** (like full Wikipedia articles or long reviews).

---

## ðŸ“Š Benchmarks

| Dataset   | Version             | Time (sec) | Speedup |
|-----------|---------------------|------------|---------|
| Synthetic | Pure Python         | 9.39       | 1.0x    |
| Synthetic | Cython              | 7.34       | 1.28x   |
| Synthetic | Cython + MP         | 4.49       | 2.09x   |
| IMDb      | Pure Python         | 2.71       | 1.0x    |
| IMDb      | Cython              | 2.52       | 1.08x   |
| IMDb      | Cython + MP         | 2.30       | 1.18x   |
| News      | Pure Python         | 1.98       | 1.0x    |
| News      | Cython              | 1.50       | 1.32x   |
| News      | Cython + MP         | 1.62       | 1.22x   |

ðŸ“Œ **Note**: Longer text = more benefit from optimization.

---

## ðŸ›  Project Structure

cython-speedup-pipeline/
â”œâ”€â”€ pure_python/                # Pure Python baseline implementation
â”‚   â”œâ”€â”€ pipeline.py             # Tokenization and processing logic (Python)
â”‚   â”œâ”€â”€ benchmark.py # Benchmarking on synthetic dataset
â”‚   â”œâ”€â”€ benchmark_imdb.py      # Benchmarking on IMDb reviews
â”‚   â””â”€â”€ benchmark_news.py      # Benchmarking on news headlines
â”‚
â”œâ”€â”€ cython_version/            # Cython-optimized versions
â”‚   â”œâ”€â”€ pipeline.pyx           # Cython implementation of text processor
â”‚   â”œâ”€â”€ setup.py               # Cython build script
â”‚   â”œâ”€â”€ benchmark.py
â”‚   â”œâ”€â”€ benchmark_imdb.py
â”‚   â””â”€â”€ benchmark_news.py
â”‚
â”œâ”€â”€ data/                      # Text datasets (ignored in Git)
â”‚   â”œâ”€â”€ imdb_reviews.csv
â”‚   â”œâ”€â”€ news_headlines.csv
â”‚   â””â”€â”€ synthetic_large_text.csv
â”‚
â”œâ”€â”€ results/                   # Benchmark output and visualizations
â”‚   â”œâ”€â”€ benchmark_results.csv  # Raw timing data
â”‚   â”œâ”€â”€ benchmark_results.md   # Table format of benchmark
â”‚   â””â”€â”€ benchmark_plot.png     # Visual comparison bar chart
â”‚
â”œâ”€â”€ notebook/
â”‚   â””â”€â”€ benchmark_plot.ipynb   # Jupyter notebook to visualize benchmark data
â”‚
â”œâ”€â”€ generate.py      # Script to generate synthetic large text
â”œâ”€â”€ generate_imdb.py           # Script to download IMDb dataset
â”œâ”€â”€ generate_news.py           # Script to download news headlines dataset
â””â”€â”€ README.md                  # Documentation for project

## Generate Datasets
This will create the CSV files in the data/ folder:
```
python generate_synthetic.py
python generate_imdb.py
python generate_news.py
```
## How to Run Benchmarks
Run the benchmark scripts for each version below:

## Pure Python
```
python pure_python/benchmark.py
python pure_python/benchmark_imdb.py
python pure_python/benchmark_news.py
```
## Cython
```
python cython_version/benchmark.py
python cython_version/benchmark_imdb.py
python cython_version/benchmark_news.py
```
## Cython + Multiprocessing
```
python cython_version/benchmark_parallel.py
python cython_version/benchmark_imdb_parallel.py
python cython_version/benchmark_news_parallel.py
```
